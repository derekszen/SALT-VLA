import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')

import os
import json
import time
import torch
import numpy as np
import multiprocessing as mp
from torch.utils.data import Dataset, DataLoader
from decord import VideoReader, cpu

class SSv2Dataset(Dataset):
    def __init__(self, data_root, annotation_file, num_frames=16, resolution=224):
        self.data_root = data_root
        self.num_frames = num_frames
        self.resolution = resolution

        with open(annotation_file, "r") as f:
            self.metadata = json.load(f)

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        item = self.metadata[idx]
        vid_id = item['id']
        video_path = os.path.join(self.data_root, f"{vid_id}.webm")

        try:
            vr = VideoReader(video_path, ctx=cpu(0), width=self.resolution, height=self.resolution, num_threads=1)
            total_frames = len(vr)
            indices = np.linspace(0, total_frames - 1, self.num_frames).astype(int)
            video_data = vr.get_batch(indices).asnumpy()
            buffer = torch.from_numpy(video_data).permute(3, 0, 1, 2).float() / 255.0
            label = item.get('label', 'unknown')
            return buffer, label
        except Exception as e:
            return torch.zeros((3, self.num_frames, self.resolution, self.resolution)), "error"

def final_test(batch_size, num_workers, prefetch_factor):
    """Final validation test for BS=64."""
    ROOT = "/mnt/ssv2"
    JSON = "/mnt/ssv2/test.json"

    print(f"\n{'='*70}")
    print(f"üéØ FINAL TEST: BS={batch_size} | Workers={num_workers} | PF={prefetch_factor}")
    print(f"{'='*70}")

    ds = SSv2Dataset(ROOT, JSON, resolution=224)
    mp_context = "forkserver" if "forkserver" in mp.get_all_start_methods() else "spawn"

    try:
        dl = DataLoader(
            ds,
            batch_size=batch_size,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=True,
            persistent_workers=True if num_workers > 0 else False,
            prefetch_factor=prefetch_factor if num_workers > 0 else None,
            multiprocessing_context=mp.get_context(mp_context) if num_workers > 0 else None
        )

        start = time.time()
        batch_times = []
        num_batches = 100

        print(f"üöÄ Running 100-batch validation...")

        for i, (batch, _) in enumerate(dl):
            if i >= num_batches:
                break

            batch_start = time.time()

            if torch.cuda.is_available():
                batch = batch.cuda(non_blocking=True)
                torch.cuda.synchronize()

            batch_time = time.time() - batch_start
            batch_times.append(batch_time)

            if i % 10 == 0:
                elapsed = time.time() - start
                fps = ((i + 1) * batch_size) / elapsed
                vram_gb = torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0
                print(f"   [{i:3d}/100] FPS: {fps:6.2f} | VRAM: {vram_gb:.2f} GB | Batch: {batch_time*1000:.1f} ms")

        total_time = time.time() - start
        total_videos = len(batch_times) * batch_size
        fps = total_videos / total_time
        avg_time = np.mean(batch_times) * 1000

        print(f"\n‚úÖ SUCCESS!")
        print(f"   ‚Ä¢ Videos/sec: {fps:.2f}")
        print(f"   ‚Ä¢ Avg batch time: {avg_time:.1f} ms")
        return True

    except Exception as e:
        print(f"\n‚ùå FAILED: {e}")
        return False

if __name__ == "__main__":
    print("üéØ FINAL VALIDATION - Attempting BS=64 with minimal resources")

    # Try BS=64 with absolute minimum workers and prefetch
    configs = [
        {'batch_size': 64, 'num_workers': 4, 'prefetch_factor': 2},
        {'batch_size': 64, 'num_workers': 2, 'prefetch_factor': 2},
        {'batch_size': 64, 'num_workers': 1, 'prefetch_factor': 2},
    ]

    for config in configs:
        success = final_test(**config)
        if success:
            print(f"\nüéâ FOUND WORKING CONFIG FOR BS=64!")
            print(f"   BATCH_SIZE = 64")
            print(f"   NUM_WORKERS = {config['num_workers']}")
            print(f"   PREFETCH_FACTOR = {config['prefetch_factor']}")
            break
        print(f"\n‚è∏Ô∏è  Pausing before next attempt...")
        time.sleep(3)
    else:
        print(f"\n‚ùå BS=64 is not achievable with current system configuration")
        print(f"\n‚úÖ CONFIRMED STABLE CONFIGURATION:")
        print(f"   BATCH_SIZE = 32")
        print(f"   NUM_WORKERS = 8")
        print(f"   PREFETCH_FACTOR = 4")
        print(f"   Expected throughput: ~238 videos/sec")
