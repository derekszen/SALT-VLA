# SALT-VLA Progress Snapshot
# Last updated: 2026-01-06 (based on archived log)

Goal
- Train a SoTA ViT-Base vision encoder for VLA using V-JEPA self-supervised learning.

Current setup
- Teacher: VideoMAE v1-Huge (Tianjiao-Yu/videomae-huge)
- Student: ViT-Base patch16 224
- Predictor: 12-layer transformer (384 dim, 6 heads)
- Dataset: Something-Something v2
- Cached latents: /mnt/ssv2/cached_latents_v1huge/train (metadata.json present)
- DataLoader masking: use_dataloader_masks=True

Most recent run (completed)
- Script: train_vitb_exp1_higherlr_vicreg10.py (10 epochs)
- RUN_NAME: vitb_exp1_higherlr_vicreg10_v1huge
- Log: /home/derekszen/Projects/SALT-VLA/run_logs/vitb_exp1_higherlr_vicreg10_v1huge_20260106_165129_pid1197207.log
- WandB: c1sk8d6s (local dir: /home/derekszen/Projects/SALT-VLA/wandb/run-20260106_165135-c1sk8d6s)
- Result: min loss 10.6725 @ step 46160; last logged step 52760, last loss 11.6332
- Exit: 2026-01-06 19:11:55 [INFO] Process exiting (no traceback)

Best results so far
- Higher LR (3e-4) achieved min loss ~10.40 (pre v1-huge cache run).
- v1-huge 3-epoch run best loss ~10.50, last-100 avg ~11.575 (plateau).

Recent changes
- Teacher switched to VideoMAE v1-Huge; cache rebuilt in /mnt/ssv2/cached_latents_v1huge.
- DataLoader now emits multi-block masks; legacy loader kept at src/data/loader_legacy.py.
- Run-level logging added to src/train.py (run_logs/ with signal handlers).

Next steps
- Decide next run: tune VICReg weights (variance/covariance) or try combined LR + mask_ratio=0.9.
- Run from /mnt/Projects/SALT-VLA to keep logs in this repo copy (current run logs are under /home/derekszen/Projects/SALT-VLA).
- Keep target loss <10.0 for publication.
